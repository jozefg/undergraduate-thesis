\section{A Step-Indexed Logical Relation}\label{sec:steps}

Before diving into the various approaches for constructing a logical
relation without step-indexing, it is well worth the time to see how a
logical relation can be done with it. The purpose of this section is
to sketch the complications intrinsic to any logical relation for
state and show how step-indexing obliterates them, though at a high
cost.

Our logical to begin with a mapping from types to semantic types
(merely sets of terms). In order to handle impredicative polymorphism
we use Girard's method~\citep{Girard:71,Girard:72}, see
\citet{Harper:16} for an introduction of the technique. This means
that our logical relation is of the form
\[
  \den{-}_{-} : \types \to \typesEnv \to \pow{\term \times \term}
\]
The central challenge is of course the meaning of $\den{\cmd{\tau}}$:
the action of the logical relation at commands. At an intuitive level,
for two commands are rather like (partial) functions: they map heaps to heaps
and a return value. Drawing inspiration from how logical relations for
functions are defined, we might write the following for the definition
the logical relation.
\begin{align*}
  \den{\cmd{\tau}}_\eta& \triangleq \{(e_1, e_2) \mid\\
  &\exists m_1, m_2.\ \steps{e_i}{\cmd{m_i}} \land{}\\
  &\forall h_1 \sim h_2.
  \ (m_1, h_1) \simeq (m_2, h_2) \land{}\\
  &\quad \forall v_1, h_1', v_2, h_2'.
  \ (\stepsM{m_1}{h_1}{\ret{v_1}}{h_1'} \land \stepsM{m_2}{h_2}{\ret{v_2}}{h_2'})\\
  &\qquad \implies (h_1' \sim h_2' \land (v_1, v_2) \in \den{\tau}_\eta)
\end{align*}
Here left undefined is the definition of $\sim$ between two
heaps. This is in fact a major issue because there appears to be no
good way to identify when two heaps ought to be equal. The first issue
here is that semantic equality of terms (be it contextual or logical)
is type-indexed. This means that in order to compare heaps pointwise
for equality (a reasonable first approach) requires that we at least
know the types of the entries. Furthermore, we should not compare these
heaps for equality at all locations necessarily, two heaps should only
need to agree on the cells that the programs are going to use.

These two caveats are important if we want to prove programs to be
equivalent which do not use the heap identically. For instance,
consider the two programs:
\[
  \dcl{\alpha}{1}{\ret{\cmd{\get{\alpha}}}} \qquad\qquad
  \ret{\cmd{\ret{1}}}
\]
These are contextually equivalent (the assignable of the first program
is hidden from external manipulation) and yet they allocate in
different ways. So $\sim$ must not be \emph{merely} pointwise equality
of all cells in the most general case. It is also easy to see that
proving that the programs above are equal requires showing that
$h_1 ~ h_2$ if and only if $h_1(\alpha) = 1$. That is, this program
doesn't merely require that heap cells contain values of some
syntactic type, but they may need to belong to an arbitrary semantic
type.

In order to reconcile these constraints, one thing is clear: the
logical relation must somehow vary depending on the state that the
heap is supposed to be in. It is simply not the case that programs
that are equivalent in a heap where no cells are required to exist if
and only if they're equivalent in a heap where one cell is required to
exist.

The solution to this is called a Kripke logical relation. Kripke
logical relations, more generally sheaf models, are a recurring
phenomenon in computer
science~\citep{Plotkin:80,Mitchell:91,Appel:01,Ahmed:04}. The
underlying idea of Kripke logical relations, or sheaf models, is to
abandon the notion of a single global truth and judge truth relative
to a current state of the world. The notion of ``state of the world''
varies from application to application but is always a described as
a partially ordered set, $\worlds$. Elements of $\worlds$ represent
the different states of knowledge we may have about the world and the
partial order, $w_1 \reach w_2$ describes when $w_2$ is a consistent
expansion of the knowledge of $w_1$.

For a Kripke logical relation rather than considering
$\den{\tau}_\eta$ we work relative to a world $w$:
$(e_1, e_2) \den{\tau}_\eta(w)$. Importantly, Kripke logical relations
should be monotone in relation to $\reach$:
\[
  \forall w_1, w_2.
  \ w_1 \reach w_2 \land (e_1, e_2) \in \den{\tau}_{w_1}
  \implies (e_1, e_2) \in \den{\tau}_{w_2}
\]
Intuitively, if we know that some fact holds at a world, $w_1$, and we
add more knowledge to $w_1$ to reach $w_2 \breach w_1$ it should not
reduce what we know to be true. Put in a more philosophical way: the
absence of knowledge does not imply its negation.

In this case, the choice of Kripke world is meant to be express the
current state of the heap that programs are being compared at, or at
least, what is known about it. What is this world concretely however?
As a first cut, one could consider a simple collection of symbols and
types. That is,
$\worlds \triangleq \powfin{\assignables \times \types}$ equipped with
$\subseteq$. We can change our clause for the logical relation to take
these worlds into account.
\begin{align*}
  \den{\cmd{\tau}}_\eta\different{(w_1)}& \triangleq \{(e_1, e_2) \mid\\
  &\exists m_1, m_2.\ \steps{e_i}{\cmd{m_i}} \land{}\\
  &\forall \different{w_2 \breach w_1}.\ \forall h_1 \different{\sim_{w_2}} h_2.
  \ (m_1, h_1) \simeq (m_2, h_2) \land{}\\
  &\quad \forall v_1, h_1', v_2, h_2'.
  \ (\stepsM{m_1}{h_1}{\ret{v_1}}{h_1'} \land \stepsM{m_2}{h_2}{\ret{v_2}}{h_2'})\\
  &\qquad \implies (\different{\exists w_3 \breach w_2}.
    \ h_1' \different{\sim_{w_3}} h_2' \land (v_1, v_2) \in \den{\tau}_\eta\different{(w_3)})
\end{align*}
These changes are largely forced. We must quantify over all possible
$w_2$ extending $w_1$ at the beginning: if this was elided then
$\den{\cmd{\tau}}_\eta$ would not be monotone. The extension at the
end, $w_3 \breach w_2$, is so that the world may be updated to reflect
the changes that were caused by allocating new cells or updating
existing ones. Still unexplained is $h_1 \sim_w h_2$. At this point it
can be defined in a slightly more refined way since $w$ at least
specifies what cells we ought to compare for equality. The notion of
equality that we want is problematic though.
\begin{itemize}
\item If some stronger notion of equality than logical equivalence,
  such as $\alpha$-equivalence, is used the fundamental theorem will
  fail in the clause for $\set{\alpha}{e}$.
\item If a weaker equality than logical equivalence is used then the
  fundamental theorem will fail in the clause for $\get{\alpha}$.
\item If logical equivalence itself is used, the definition is will
  become ill-founded. This is because the heap may contain cells with
  a type larger than $\cmd{\tau}$.
\end{itemize}
What is needed is an maneuver in the vein of Girard's method. Instead
of attempting to decide what the equality for a particular heap
location should be in the definition of $\sim_w$, it should be told to
us already by $w$. This idea, originating with the very early work on
denotational models of state, means that our Kripke worlds should
instead satisfy the relation:
\[
  \worlds = \assignables \pto \pow{\term \times \term}
\]
Now the world extension relation is defined by the following.
\[
  w_1 \reach w_2 \triangleq
  \dom(w_1) \subseteq \dom(w_2) \land
  \forall \alpha.\ w_1(\alpha) = w_2(\alpha)
\]
This version is much more plausible. With the definition of the clause
of the logical relation described previously together with the
following definition of $\sim_w$ the logical relation is well-defined.
\[
  h_1 \sim_w h_2 \triangleq \forall \alpha \in \dom(w).
  \  (h_1(\alpha), h_2(\alpha)) \in w(\alpha)
\]
The issue here is more subtle and causes the fundamental theorem to
fail in the rule for allocation: what relation should we pick when a
fresh cell is allocated? It seems that the only choice when allocating
a cell of type $\tau$ at world $w$ is to extend our world with
$\alpha \mapsto \den{\tau}_\eta(w)$. The complication arises when we
allocate more cells later and move to a fresh world. The relation at
$\alpha$ is now stale, it refers to an outdated world and doesn't
allow for equivalences which are true at this new world but were
previously false. To concretely see this, consider the program:
\begin{align*}
  \cmd{
    &\dcl{\alpha}{\lam{x}{\nat}{\cmd{\ret{1}}}}{\\
      &\quad \ret{\cmd{\set{\alpha}{\lam{x}{\nat}{
          \bnd{x}{\cmd{\get{\alpha}}}{\\ & \qquad\qquad\qquad\qquad\ret{x + 1}}
        }}}}
    }
  }
\end{align*}
This style of program is used to encode recursion in this language in
general. In this case, however, the central point of interest is that
$\alpha$ is updated to contain a command which mentions $\alpha$. In
logical relation, $\alpha$ could only ever contain terms in
$\den{\fn{\nat}{\cmd{\nat}}}(\emptyset)$. In particular, this never
includes a command which mentions $\alpha$. This prevents this
perfectly type safe program from being included in the logical
relation and so the fundamental theorem must fails.

What is to be done here? The root of the issue is that when we
allocate a cell it is impossible to determine precisely what programs
will occupy it because programs in the cell may mention cells that are
yet to be allocated at the time of the construction. What is needed is
for the semantic type stored in a heap cell to vary according to the
world. This fixes an asymmetry between the Kripke world and the
logical relation: the Kripke world supposedly maps locations to
semantic types but the semantics types (as determined by the logical
relation) vary of the Kripke worlds. This leads us to the final form
of the definition of Kripke worlds.
\[
  \worlds = \assignables \pto (\worlds \to \pow{\term \times \term})
\]
Herein lies the rub: this definition of the set of worlds is precisely
what is required for this logical relation but it is not a set. A
simple cardinality argument shows that there can be no such set since
it would have to be larger than its own power set. This is not an
easily avoided problem. It is unknown how to simply avoid this using
ingenuity in the choice of the Kripke world.

This is where step-indexing enters the picture. Step-indexing after
all was introduced to break precisely these sort of circularities and
solve recursive equations up to an approximation.

With step-indexing, the space of semantic types becomes indexed by
natural numbers and we will likewise index the world by these same
natural numbers. The idea is that a world at stage $n$ maps to
assignables to semantic types which only vary at the previous $n - 1$
stages, past $n - 1$ they are simply constant. The issue is that this
approach requires a number of complex definitions which obscure the
underlying intent: to solve this recursive equation.

Instead of slogging through the classical step-indexed definitions, we
will make use of a more modern categorical approach. Instead of
working with sets, from the beginning we will work with sets varying
over natural numbers: presheaves over $\omega$.
\begin{defn}
  A presheaf over a category $\Ccat$ is a functor from $\op{\Ccat}$ to
  $\SET$. Presheaves form a category with morphisms being natural
  transformations. This category is written $\presheaves{\Ccat}$.
\end{defn}
\begin{example}
  A presheaf over $\omega$ is a family of sets $(X_i)_{i \in \nat}$
  with a map $r_n : X_{n + 1} \to X_n$ for all $n$ called restriction
  maps. A map between presheaves is then a family of maps
  $f_n : X_n \to Y_n$ so that the following commutes for all $n$.
  \[
    \begin{tikzcd}
      X_{n + 1} \ar[r, "f_{n + 1}"] \ar[d, swap, "r_n"] & Y_{n + 1} \ar[d, "r_n"]\\
      X_n \ar[r, swap, "f_n"] & Y_n
    \end{tikzcd}
  \]
\end{example}
Rather than working directly with sets then, we can instead work with
presheaves synthetically. For instance, we can define the exponential
of two presheaves rather than mucking about to create an implication
which interacts properly with the step.
\begin{lem}
  The (co)limit\footnote{A generalization of products and sums.} of
  presheaves exists for all small diagrams and is determined
  pointwise.
\end{lem}
The above theorem tells us, for instance, that if we want to form the
product of two presheaves, $X$ and $Y$, over $\omega$, at time $n$ it's just the
product of the $X(n)$ and $Y(n)$. More generally, this lemma gives a
wide-variety of ways to construct complex presheaves from simple ones
without ever having to deal with the step manually. The main missing
element is the ability to form exponentials, the categorical analog of
functions. For presheaves these are slightly more complicated since
the function must respect the indexing structure.
\begin{lem}
  Given two presheaves $X, Y : \presheaves{\Ccat}$, the exponential
  between them is
  \[
    (Y^X)(c) \triangleq \hom(\yoneda(c) \times X, Y)
  \]
  where $\yoneda$ is the Yoneda embedding, defined by the following.
  \[
    \yoneda(c) = hom_\Ccat(-, c)
  \]
\end{lem}
This definition may seem abstract but it is, importantly, monotone and
so determines a valid presheaf. The real power of this approach is
that \emph{it does not matter} that this definition is complex. The
point is that this definition determines a function of presheaves in
that it contains elements we can apply and only elements we can
apply. Beyond these two facts its construction is entirely
irrelevant. The categorical methodology, after all, is to only care
about how an object relates through morphisms to the rest of the
category. % TASTE IT.

The constructions so far have given us a wide variety of constructible
presheaves but nothing thus far has increased our expressive power of
what we had in $\SET$. For that we need the ability to solve certain
recursive equations. In fact, it will turn out that we can solve
\emph{guarded} domain equations in $\presheaves{\omega}$. In order to
see this, first let us define a functor on $\presheaves{\omega}$.
\begin{defn}
  The later functor,
  $\later : \presheaves{\omega} \to \presheaves{\omega}$, is defined
  on objects as follows.
  \begin{align*}
    (\later X)(n + 1) &= X(n)\\
    (\later X)(0) &= \{\star\}
  \end{align*}
  This family of sets is a presheaf in the obvious way:
  $r_0 = \lambda x.\ \star$ and $r_{n + 1}$ is the $r_n$ of $X$. The
  action on morphisms is as follows.
  \begin{align*}
    (\later f)(n + 1) &= f_n\\
    (\later f)(0) &= \lambda x.\ \star
  \end{align*}

  The later functor comes equipped with a natural transformation
  $\delay : 1 \to \later$. Explicitly, this means $\delay$ is a family
  of maps $\delay_X : X \to \later X$ so that
  $\delay_Y \circ f = f \circ \delay_X$ for any $f : X \to Y$.
\end{defn}
The later modality is the logical essence of step-indexing.
After all, the key insight of step-indexing is actually two-fold:
\begin{enumerate}
\item In order to show that two programs are indistinguishable, it
  suffices to show that they're indistinguishable for $n$ steps for
  any $n$.
\item When showing that two programs are indistinguishable from other
  programs at $n$ steps it suffices to show that subcomponents are
  only indistinguishable for $n - 1$ steps.
\end{enumerate}
If this second point was not the case, then it would never be possible
to decrement the step-index and the exercise would have been largely
moot. The later modality internalizes the idea of ``$n - 1$ steps''
without ever mentioning $n$. Using $\later X$ we can talk about
(uniformly) constructing an element at stage $n$ from an element at
stage $n - 1$. The $\delay$ operation even crystallizes the
monotonously of the logical relation: if we have an element at stage
$n$ we can always construct one at stage $n - 1$.

A crucial point about using natural numbers for step-indexing is that
natural numbers are well-founded; there's no way to pick a natural
number that we can decrement forever. This justifies reasoning by
induction on the natural numbers and, in particular
constructing an object at any stage provided we can take a
construction of it at stage $n - 1$ and construct it at stage
$n$. This principle may be expressed with the later modality: it's
precisely the existence of a family of morphisms:
\[
  \fix_A : A^{\later A} \to A
\]
These morphisms allow us to take a particular sort of fixed-point at
any level of maps $\later A \to A$. These morphisms belong to the
class of contractive morphisms: morphisms $X \to Y$ that can be
factored as $X \to \later X \to Y$. In particular, suppose we have
some $f : B \times \later A \to A$. Then the following equality holds:
\[
  \fix_A \circ \transpose{f} = f \circ \pair{1}{\delay_A \circ \fix_A \circ \transpose{f}}
\]
Written out using more type-theoretic notation this is easier to
process.
\[
  \forall a, b.\ \fix_A(f(b, -))(a) = f (b, \delay_A(\fix_A(f(b))(a)))
\]
This fixed-point construction allows us to build many interesting
structures inside this category. Through the inclusion of
universes~\citep{Hofmann:90s}, one can even construct solutions to
certain (small) domain equations entirely internally to the
category~\citep{Birkedal:13}. The basic idea is that
$\presheaves{\omega}$ can be easily made to support an object,
$\mathcal{U}$, for which global sections classify other smaller
objects. This is the categorical analog of a Grothendieck
universe~\citep{Streicher:04} and proves to be an important
concept in the semantics of dependent type theory. Then, by using
$\fix_\univ$ it is possible to construct the recursively defined
presheaves necessary to build logical relations. This approach, while
not always explicit, is latent in the work done in constructing logical
relations in guarded type theory and guarded
logics~\citep{Dreyer:09,Paviotti:15,Krogh-Jespersen:17}.

We will consider the more traditional approach of using proper domain
equations rather than just small ones. With this methodology, we model
equations as functors and fixed points of them as solutions. This
approach in domain theory originates from \citet{Smyth:77} and
subsumed prior work by \citet{Scott:76} constructing recursive domain
equations by hand.

One potential issue is that we would like to solve domain equations
which are not strictly speaking functorial. In particular, we want to
handle the case where the equation contains both positive and negative
occurences. We handle these by viewing them as functors
$F : \op{\presheaves{\omega}} \times \presheaves{\omega} \to
\presheaves{\omega}$
in the style of \citet{Pitts:96} for instance. The question then
becomes, for what functors can we construct an object, $I$, so that
$F(I, I) \cong I$, an invariant object. This construction is a
generalization of the theorem of America and
Rutten~\citep{America:87}. The precise accounting the theorem can be
found in \citet{Birkedal:domain:10,Birkedal:steps:11} allowing for any
enriched functor between categories enriched in sheaves over a
complete Heyting algebra with a well-founded basis. For our purposes
though a much less general theorem suffices.
\begin{defn}
  A functor, $F$, is said to be locally contractive if there is a
  family of contractive morphisms
  \[
    f_{X_1, X_2, Y_1, Y_2} :
    X_1^{X_2} \times Y_2^{Y_1} \to F(X_2, Y_2)^{F(X_1, Y_1)}
  \]
  So that this family is family respects composition and identity and
  so that for each $\pair{g}{h} : 1 \to X_1^{X_2} \times Y_2^{Y_1}$
  then the following equation holds.
  \[
    f_{X_1, X_2, Y_1, Y_2} \circ \pair{g}{h} =
    \transpose{F(\transpose{g}, \transpose{h})}
  \]
  If just the latter condition holds (no respect for identity or
  composition) $F$ is said to have a strength $f$ and if the family of
  morphisms is not contractive we shall call the functor locally
  nonexpansive.
\end{defn}
This definition is subtly different than some presentations of this
theorem, which require only that $F$ have a strength comprised of
contractive morphisms. This version essentially states that $F$ must
be an enriched functor for the category $\presheaves{\omega}$ enriched
over itself. The central theorem, Theorem~\ref{thm:steps:fixed-points}
is true even in this weakened version but I am unable to find a proof
of this fact and I cannot list a theorem that I cannot prove
myself. The relative strengthening that this generality provides seems
vacuous as well, none of the examples of the fixed point theorem used
either in this section or Section~\ref{sec:guarded} require it.
\begin{example}
  The functors $\times$, $\to$, and $+$ are all locally
  nonexpansive. The functor $\later$ is locally
  contractive. Additionally, any locally contractive functor is locally
  nonexpansive.
\end{example}
\begin{lem}
  The composition of locally nonexpansive functors is locally
  nonexpansive. The composition of a locally contractive functor with
  a locally nonexpansive functor is locally contractive.
\end{lem}
We may now state the theorem which makes working a
$\presheaves{\omega}$ so appealing.
\begin{thm}\label{thm:steps:fixed-points}
  For any locally contractive functor $F$ there exists an object $I$,
  unique up to isomorphism, so that $F(I, I) \cong I$.
\end{thm}
This theorem allows us to solve a wide variety of domain equations,
including a small modification of the crucial one for Kripke
worlds. First, let us define $\upred{S}$ as a ``time varying
predicate'' on a set $S$. This will be the analog of the sets of terms
used in step-indexed models.
\[
  \upred{X}(n) \triangleq \{(m, x) \mid x \in X \land m < n\}
\]
There is an evident restriction mapping sending a uniform predicate at
stage $n + 1$ to the uniform predicate containing the entries indexed
by numbers smaller than $n$. Next, the presheaf of partial maps from
assignables to presheaves can be defined as follows:
\[
  (\assignables \pto X)(n) \triangleq
  \{f \in X(n)^{F} \mid F \subseteq \assignables \land F\ \mathsf{finite}\}
\]
Importantly, it is not hard to see that $\assignables \pto -$ defines
a functor which is locally nonexpansive. The final piece necessary is
a subobject of the exponential $Y^{\assignables \pto X}$ which
isolates those functions which are monotone. In order to define this,
we must assume that $Y$ comes equipped with a partial order. Viewed
from the external perspective this is a family of relations indexed by
natural numbers which respects reindexing. If one views the partial
order internally, however, it is just a normal partial order presented
categorically. The subobject desired can be defined internally in a
way which is obviously correct using the internal logic of
$\presheaves{\omega}$ as follows.
\begin{align*}
  (\assignables \pto X) \mto Y &\triangleq \\
  \{f : Y^{\assignables \pto X} \mid{}&
   \forall w_1 w_2 : \assignables \pto X.\ w_1 \reach w_2 \implies f(w_1) \le f(w_2)\}
\end{align*}
Constructed externally this presheaf is somewhat more difficult to
construct, but still quite possible. It's
\begin{align*}
  ((\assignables \pto X) \mto Y)(n) &= \\
  \{f : (Y^{\assignables \pto X})(n) \mid{}&
   \forall m \le n.\ \forall w_1, w_2 : (\assignables \pto X)(n).\\
  &\qquad w_1 \reach_n w_2 \implies f(m)(\star, w_1) \le_n f(m)(\star, w_2)\}
\end{align*}
This external definition is neither more precise nor more intuitive,
so it is more helpful to read the internal version and understand that
all the quantifiers in the predicate implicitly handle the steps
correctly. A more technical discussion of the internal language of
$\presheaves{\omega}$ is postponed until the end of this section.

At the end of these constructions, we may define the following
contractive functor.
\[
  X \mapsto \later ((\assignables \pto X) \mto \upred{\term \times \term})
\]
Solving this for a fixed point gives the desired presheaf of Kripke
worlds. Defining the rest of the logical relation proves to be quite
straightforward now that the right definition of Kripke worlds is in
place. The type of our logical relation is slightly different now,
it's defined as a monotone map:
\[
  \den{-}_{-} : \types \to \typesEnv \to \worlds \mto \upred{\term \times \term}
\]
Here $\mto$ is an subobject of the exponential in the presheaf
category so it is indexed by natural numbers and subject to a
naturality condition. Then the crucial clause of our logical relation
can be defined as follows.
\begin{align*}
  \den{\cmd{\tau}}_\eta(n)(w_1)& \triangleq \{(k, e_1, e_2) \mid
  k_1 \le n \land \exists m_1, m_2.\ \steps{e_i}{\cmd{m_i}} \land{}\\
  &\forall w_2 \breach_{k_1} \different{r_{k_1}^n(w_1)}.\ \forall h_1 \different{\sim_{w_2}^{k_1}} h_2.
  \ (m_1, h_1) \simeq (m_2, h_2) \land{}\\
  &\quad \different{\forall d.}\ \forall v_1, h_1', v_2, h_2'.
  \ (\stepsM[\different{d}]{m_1}{h_1}{\ret{v_1}}{h_1'} \land \stepsM{m_2}{h_2}{\ret{v_2}}{h_2'})\\
  &\qquad \implies (\different{\exists w_3 \breach r^{k_2 - d}w_2}.
    \ h_1' \different{\sim_{w_3}} h_2' \land (v_1, v_2) \in \den{\tau}_\eta(k_2 - d)\different{(w_3)})
\end{align*}
We can now also define $\sim$ making use of the following isomorphism.
\[
  \iota : \worlds \cong
  \later (\assignables \pto \worlds \mto \upred{\term \times \term})
\]
The following definition is then quite naturally expressed
internally. The external version merely involves a preponderance of
indices. Let us suppose that $w$ is a world at step $n$
\begin{align*}
  h_1 &{}\sim_w h_2 \defs\\
  &\begin{cases}
    \forall \alpha \in \dom(\iota(w)).\ (n - 1, h_1(\alpha), h_2(\alpha)) \in \iota(w)(\alpha)(r^{n - 1}(w))
    & n > 1\\
    \text{true} & \text{otherwise}
  \end{cases}
\end{align*}
The essence of the definition is the self-application. A heap is
related to another heap at a world if all of the points are related
relative to the same world. It was this circularity and
self-application which drove us to step-indexing in the first place.

The rest of the logical relation is entirely standard step-indexing
and the curious reader is referred to \citet{Ahmed:04}.

A final consideration here is that the version of step-indexing
presented in this paper is ``half-baked''. We have eschewed explicit
indexing in the entire construction of the semantic domains and made
use of $\later$ and presheaves, but then chosen to define the logical
relation with explicit indexing. All the same issues that applied to
the construction of the domain of discourse for the logical relation
apply the actual definition of the logical relations itself. Since our
definition of the logical relation is just constructing a subpresheaf
pointwise using standard logical formula and passing around the index,
can we isolate the handling of the index and abstract away from it?

A powerful approach to handling this comes from topos theory. Topos
theory is a subfield of category theory concerned with studying
categories which are similar to $\SET$. It is a standard result in
topos theory that all presheaf categories are toposes and so all the
tools of topos theory are applicable to $\presheaves{\omega}$. For
instance, the explicit definition of $\upred{A}$ can be replaced with
the topos theoretic definition of power sets. Of particular interest
is the ``internal logic\footnote{In fact, the internal logic of a
  topos can be generalized to a full dependent type theory with a
  distinguished impredicative universe. This type theory provides even
  more flexibility than the logic. In it, we could have defined the
  entirety of our construction of Kripke worlds in a setting just like
  programming in type theory.}'' of the topos. It turns out that
$\presheaves{\omega}$ supports a version of intuitionistic
higher-order logic whose interpretation is precisely the standard
set-theoretic interpretation with a little extra work to pass around
the index. Importantly, one can take a presheaf, $A$, and a predicate,
$\phi$, on it and form a subpresheaf $\{ a \in A \mid \phi(a) \}$ so
that every element of this comprehension satisfies $\phi$ as one would
hope.

The internal logic of $\presheaves{\omega}$ includes everything we
need to define our logic including even version of L\"ob induction and
a logical version of later, $\ilater$. Working this way sweeps the
step-index entirely under the rug and obliterates the requirement to
perform explicit index math anywhere. Instead, the frustrating
mismatch of having a fact at $n - 1$ and needing it at $n$ manifests
through having $\ilater \phi$ and needing $\phi$. Proper index
discipline is replaced by the proper handling of the later
modality. For instance, here is the definition of world satisfaction
working in the internal logic.
\[
  h_1 \sim_w h_2 \triangleq
  \forall \alpha \in \dom(w).
  \ \sincl{\iota(w) \zap \delay(w) \zap (h_1, h_2)}
\]
No explicit steps are present only a handful of logical operations to
handle the new type-constructor later. This approach to step-indexing,
whether explicitly topos theoretic or not is the subject of a long
line of work~\citep{Svendsen:16}. Importantly, this logical
approach to step-indexing enables abstraction from the natural numbers
themselves and suggests more general notions of
step-indexing~\citep{Svendsen:16}. The most approachable introduction to
this approach is \citet{Dreyer:09} and \citet{Birkedal:steps:11} provides a
thorough topos-theoretic grounding explicitly using Kripke-Joyal
semantics.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
